# Training Configuration
# Example: BFMC Dataset (replace with your own dataset paths)

# Dataset paths
dataset:
  data_yaml: "../dataset/dataset3_total2026_v2/data.yaml" # Path to data definition file
  train: "../dataset/dataset3_total2026_v2/train" # Training images directory
  val: "../dataset/dataset3_total2026_v2/valid"   # Validation images directory
  test: "../dataset/dataset3_total2026_v2/test"   # Test images directory (held out)

# Training parameters (optimized for RTX 4090 24GB)
training:
  epochs: 100         # Total training passes over the dataset
  batch_size: 16      # Images per batch (Increase if VRAM allows, decrease if OOM)
  imgsz: 640          # Input image resolution (640x640 is standard YOLO)
  patience: 20        # Stop early if no improvement for N epochs
  workers: 16         # Dataloader threads (Set close to CPU core count)
  device: 0           # GPU ID (0 for first GPU, 'cpu' for CPU)
  amp: true           # Automatic Mixed Precision (Faster, less VRAM)
  cache: true         # Cache images in RAM (Faster, uses more System RAM)

# Model-specific configurations
# These models are used when running: python3 scripts/train.py --model all
models:
  list: ["yolov8m", "yolo11s", "yolo11n","rtdetr-l"]
  pretrained: true   # Start with pretrained weights (Recommended)

# Optimization (Hyperparameters)
optimizer:
  name: "AdamW"       # Optimizer type (AdamW, SGD, etc.)
  lr0: 0.01           # Initial learning rate
  lrf: 0.01           # Final learning rate fraction (lr0 * lrf)
  momentum: 0.937     # SGD momentum/Adam beta1
  weight_decay: 0.0005 # L2 regularization term

# Augmentation (Data generation during training)
augmentation:
  hsv_h: 0.015        # Hue shift (fraction) - Simulates different lighting colors
  hsv_s: 0.7          # Saturation shift (fraction)
  hsv_v: 0.4          # Value (brightness) shift (fraction)
  degrees: 0.0        # Rotation (+/- degrees)
  translate: 0.1      # Translation (+/- fraction of image size)
  scale: 0.5          # Scale gain (+/- gain) - Zooms in/out
  shear: 0.0          # Shear angle (+/- degrees)
  perspective: 0.0    # Perspective distortion (+/- fraction), range 0-0.001
  flipud: 0.0         # Probability of vertical flip (up-down)
  fliplr: 0.5         # Probability of horizontal flip (left-right)
  mosaic: 1.0         # Probability of mosaic (combining 4 images) - Strong learner
  mixup: 0.0          # Probability of mixup (blending images)

# Inference settings (Validation/Testing thresholds)
inference:
  conf_threshold: 0.75 # Minimum confidence to count as detection
  iou_threshold: 0.45  # IoU threshold for NMS (removing duplicate boxes)
  max_det: 300         # Maximum objects detected per image

# Output paths
output:
  results_dir: "results" # Directory for training runs and comparisons
  models_dir: "export_models"   # Directory for inference.py to save the exported models
